{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Polish Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "TODAY = datetime.date.today()\n",
    "CURRENT_YEAR = TODAY.year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finds Processor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes dates are written as XX' of XXth c.; converts these expressions to yyyy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCentury(date):\n",
    "    match = re.search(r\"st|nd|th\", date) # date is in century form\n",
    "    if (match):\n",
    "        half = re.split(\"of\", date)\n",
    "\n",
    "        subCenturyText = re.search(r\"[0-9][0-9]|[0-9]\", half[0])\n",
    "        subCenturyInt = int(subCenturyText.group())\n",
    "\n",
    "        centuryText = re.search(r\"[0-9][0-9]|[0-9]\", half[1])\n",
    "        centuryInt = int(centuryText.group())\n",
    "\n",
    "        year = ((centuryInt - 1) * 100) + subCenturyInt\n",
    "        start = subCenturyText.start()\n",
    "        end = subCenturyText.end() + centuryText.end() + 8\n",
    "        date = half[0] + half[1]\n",
    "        date = date[:start] + str(year) + date[end:]\n",
    "        return date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below parses for year found. Some variation in input causes complexity here; for example, here are some inputs:\n",
    "<br>\n",
    "before Oct.2010\n",
    "<br>\n",
    "bef. 1960\n",
    "<br>\n",
    "2005 or earlier\n",
    "<br>\n",
    "around 1930\n",
    "<br>\n",
    "06 and 11.2006\n",
    "<br>\n",
    "1.11.1865\n",
    "<br>\n",
    "c. 1900-1914\n",
    "<br>\n",
    "1880s\n",
    "<br>\n",
    "21 June 1875\n",
    "<br>\n",
    "Spring 1962\n",
    "<br>\n",
    "1926/27\n",
    "<br>\n",
    "1872 or 1875\n",
    "<br>\n",
    "Therefore, new cases may need to be covered if new variations arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(find: dict, date):\n",
    "    if (re.fullmatch(r\"([0-9][0-9][0-9][0-9])+$\", date)):  # string is simple, only 4 consecutive digits, e.g. '2003'\n",
    "        find[\"year_found\"] = date\n",
    "        find[\"year_found_end\"] = date\n",
    "        return\n",
    "# at this point, date can be complex. First make sure date is not in century format\n",
    "    if (re.search(r\"[0-9](st|nd|th)\", date)):\n",
    "        date = convertCentury(date) # if century format, convert it to yyyy\n",
    "        \n",
    "    year = re.search(r\"([0-9][0-9][0-9][0-9])\", date).group() # extracted year string\n",
    "    \n",
    "    if (re.search(r\"bef|earl|pre\", date)): # if end of range specified\n",
    "        find[\"year_found\"] = \"1700\"\n",
    "        find[\"year_found_end\"] = year\n",
    "        return\n",
    "    \n",
    "    if (re.search(r\"after|later|post\", date)): # if start of range specified\n",
    "        find[\"year_found\"] = year\n",
    "        find[\"year_found_end\"] = CURRENT_YEAR\n",
    "        return\n",
    "    \n",
    "    # if full range is specified (checking for 4 digits to eliminate - being used between days: 26-27 June, 2003)\n",
    "    if (re.search(r\"[1-2][0-9][0-9][0-9]\\s*(or|/|-|to|and)\", date) and not re.search(r\"ctober\", date)):\n",
    "        year = re.findall(r\"([0-9][0-9][0-9][0-9])\", date)\n",
    "        find[\"year_found\"] = year[0]\n",
    "        if (year.__len__() != 1): # if string looks like 1991-2003\n",
    "            find[\"year_found_end\"] = year[1]\n",
    "            return\n",
    "        else: # string looks like 1961-64\n",
    "            pattern = r\"or|/|-|to|and\"\n",
    "            endYear = year[0][:2] + re.search(r\"[0-9][0-9]\", re.split(pattern, date, 1)[1]).group()  # construct full end year: 64 -> 1964\n",
    "            if (int(endYear) < int(year[0])): endYear = str(int(endYear) + 100) # in case of 1997-01\n",
    "            find[\"year_found_end\"] = endYear\n",
    "            return\n",
    "\n",
    "    if (re.search(r\"[1-2][0-9][0-9]0s\", date)): # if decade range given, e.g. 1880s\n",
    "        year = re.search(r\"[1-2][0-9][0-9]\", date).group()\n",
    "        find[\"year_found\"] = year + \"0\"\n",
    "        find[\"year_found_end\"] = year + \"9\"\n",
    "        return\n",
    "    \n",
    "    # at this point no special markers (before, after, -, etc.) left, just take the year and ignore other characters\n",
    "    find[\"year_found\"] = year\n",
    "    find[\"year_found_end\"] = year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines if findSpotName contains a digit or Roman numeral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsNumber(place) -> bool:\n",
    "    pattern = re.compile(r\"[0-9]|(\\s(I|V|X|L|C)(?=(\\s|$|I|V|X|L|C)))\")\n",
    "    if (re.search(pattern, str(place))): \n",
    "        return True\n",
    "    else: return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines what finds are single finds, hoards, and excavations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleOrHoard(freq, finds): \n",
    "    for find in finds:\n",
    "        place = find[\"Name\"]\n",
    "        year = find[\"tempYear\"]\n",
    "        if (len(freq[(place, year)]) > 1 and containsNumber(place)):\n",
    "            find[\"type_find\"] = \"Hoard\"\n",
    "            find[\"num_coins\"] = len(freq[(place, year)])\n",
    "            find[\"hoard?\"] = True\n",
    "            find[\"single?\"] = False\n",
    "            index = 1 # to keep the 0th one\n",
    "            duplicates = freq[(place, year)]\n",
    "            while (index < len(freq[(place, year)])):\n",
    "                finds.remove(duplicates[index])\n",
    "                index += 1\n",
    "        else: \n",
    "            find[\"type_find\"] = \"Single Find\"\n",
    "            find[\"num_coins\"] = 1\n",
    "            find[\"hoard?\"] = False\n",
    "            find[\"single?\"] = True\n",
    "        find[\"excavation?\"] = bool(re.search(r\"excav\", str(find[\"tempCircumstances\"]), re.IGNORECASE))\n",
    "        find.pop(\"tempYear\")\n",
    "        find.pop(\"tempCircumstances\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up dataframe as a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "finds = list()\n",
    "freq = defaultdict(list)\n",
    "years = {}\n",
    "path = \"C:/Users/there/Documents/Code/Numismatics/AFE PL 325-750 (Polish Data).xlsx\"\n",
    "theirData = pd.read_excel(path)\n",
    "for index, row in theirData.iterrows():\n",
    "    find = {}\n",
    "    find[\"FindNumber\"] = row[\"ID\"]\n",
    "    find[\"Name\"] = row[\"FindspotName\"]\n",
    "    place = find[\"Name\"]\n",
    "    year = row[\"YearFound\"]\n",
    "    freq[(place, year)].append(find)\n",
    "    find[\"lat\"] = row[\"LatitudePlace\"]\n",
    "    find[\"long\"] = row[\"LongitudePlace\"]\n",
    "    find[\"tempYear\"] = row[\"YearFound\"] # temporary, for use in singleOrHoard function\n",
    "    find[\"tempCircumstances\"] = row[\"Findcircumstances\"] # Same as above\n",
    "    try:get_date(find, row[\"YearFound\"])\n",
    "    except: # when YearFound is \"\" or \"no data\"\n",
    "        find[\"year_found\"] = \"1700\"\n",
    "        find[\"year_found_end\"] = CURRENT_YEAR\n",
    "    find[\"comments\"] = \"\"\n",
    "    find[\"imported\"] = TODAY\n",
    "    find[\"references\"] = row[\"Bibliography\"]\n",
    "    find[\"owner\"] = \"FRC-PL\"\n",
    "    find[\"created\"] = TODAY\n",
    "    finds.append(find)\n",
    "singleOrHoard(freq, finds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(finds)\n",
    "type = df.pop(\"type_find\") # rearranging two columns\n",
    "num = df.pop(\"num_coins\")\n",
    "df.insert(2, \"type_find\", type)\n",
    "df.insert(5, \"num_coins\", num)\n",
    "df.to_csv(\"final_frcpl_finds.csv\", encoding='utf16', sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMetal(symbol): # convert metal symbol\n",
    "    metal_conversion = {\n",
    "        'Ae': 'bronze', \n",
    "        'Ag': 'silver', \n",
    "        'Au': 'gold'\n",
    "    }\n",
    "    return metal_conversion.get(symbol, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDenomination(denomination): # Taken from Mark's AFE code\n",
    "    denomination_conversion = {\n",
    "    'Denarius':'denarius', 'Semis':'semissis', 'AE1': 'AE1 (6+ g.)',\n",
    "        'AE2 / AE3': 'AE2 (4-6 g.)', 'AE3 / AE2': 'AE3 (2-4 g.)',\n",
    "            'AE3 / AE4': 'AE3 (2-4 g.)', 'AE4 / AE3': 'AE4 (0.5-2 g.)',\n",
    "                'Aureus':'aureus', 'AE':'uncertain (bronze)', 'Antoninianus':'radiate or nummus (UK find)',\n",
    "                    'Follis':'follis','AE2':'AE2 (5.15g)', 'Drachme':'drachm', 'AV':'AV', 'Maiorina':'follis',\n",
    "                'AE3':'AE3 (2.58g)', 'Solidus':'solidus', 'Silber':'uncertain (silver)', 'Siliqua':'siliqua', \n",
    "            'AE4':'AE4 (1.23g)', 'Tremissis':'tremissis', '10 Num' : '10 nummi', '2 Solidi' : '2 solidi', \n",
    "         'Miliarensis' : 'miliarensis', 'Argenteus': 'argenteus', 'Bronze': 'uncertain (bronze)',\n",
    "    'Solidus / Tremissis': 'unknown old denomination', 'Siliqua (reduziert)' : 'reduced siliqua',\n",
    "    }\n",
    "    return denomination_conversion.get(denomination, \"uncertain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMint(mint): # converting mints into FLAME format\n",
    "    # Thanks for this Mark!\n",
    "    mint_conversion = {\n",
    "    'Roma':'Roma', 'Alexandria':'Alexandria ad Aegyptum', 'Uncertain mint':'Unknown', 'Constantinopolis':'Constantinople',\n",
    "       'Unofficial mint':'Unknown', 'Siscia':'Siscia', 'Thessalonica':'Thessalonika', \n",
    "       'Thessalonica / Treveri': 'Unknown (Roman Empire)', 'Roma / Treveri': 'Unknown (Western Roman Empire)',\n",
    "       'Treveri / Siscia': 'Unknown (Roman Empire)', 'Londinium':'Londinium', \n",
    "    'Treveri / Constantinopolis': 'Unknown (Roman Empire)', 'Treveri':'Colonia Augusta Treverorum', \n",
    "       'Lugdunum':'Lugdunum', 'Ticinum':'Ticinum', 'Aquileia':'Aquileia', 'Colonia CAA':'Unknown', 'Antiochia':'Antioch', \n",
    "       'Emerita':'Emerita', 'Lycia':'Unknown (East Roman)', 'Cyzicus':'Kyzikos', 'Roma / Lugdunum':'Roma or Lugdunum',\n",
    "        'Sirmium':'Sirmium', 'Eastern mint':'Unknown (East Roman)', 'Gallia':'Unknown (Gaul)', 'Unidentified mint':'Unknown',\n",
    "    'Laodicea ad Mare':'Laodicea ad Mare', 'Mediolanum':'Mediolanum', 'Constantinopolis / Mediolanum': 'Unknown (Roman Empire)', \n",
    "        'Ravenna':'Ravenna', 'Roma / Tarraco (?)':'Roma or Tarracona', 'Africa':'Unknown (Africa)', 'Hispania':'Unknown (Iberia)', \n",
    "        'Colonia Caesaraugusta':'Cesaraugusta', 'Greek East':'Unknown (East Roman)', 'Münzstätte nicht bekannt':'Unknown (Germany)', \n",
    "        'Östliche Münzstätte' : 'Unknown (Germany)', 'Sicilia' : 'Sicily', 'Syrien' : 'Unknown (Greater Syria)',\n",
    "    'Arelate' : 'Arelato', 'Heracleia' : 'Heraclea', 'Nicomedia': 'Nikomedia'\n",
    "    }\n",
    "    return mint_conversion.get(mint, 'Unknown')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines duplicates and assigns num_coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNums(groups):\n",
    "    for group in groups:\n",
    "        if (len(freq[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])]) > 1):\n",
    "            duplicates = freq[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])]\n",
    "            index = 1 # to keep 0th one\n",
    "            while (index < len(freq[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])])):\n",
    "                 groups.remove(duplicates[index])\n",
    "                 index += 1\n",
    "            group[\"num_coins\"] = len(freq[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up groups dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = list()\n",
    "freq = defaultdict(list)\n",
    "for index, row in theirData.iterrows():\n",
    "    group = {}\n",
    "    group[\"group_id\"] = index\n",
    "    group[\"name\"] = row[\"PlaceName\"]\n",
    "    group[\"frcpl_find_id\"] = row[\"ID\"]\n",
    "    group[\"mint\"] = convertMint(row[\"Mint\"])\n",
    "    group[\"denomination\"] = convertDenomination(row[\"Denomination\"])\n",
    "    group[\"start_year\"] = row[\"DateFrom\"]\n",
    "    group[\"end_year\"] = row[\"DateTo\"]\n",
    "    ruler = row[\"Issuer\"]\n",
    "    if (ruler != ruler): # sometimes nan, leaving blank cell\n",
    "        group[\"ruler\"] = \"Uncertain\"\n",
    "    else:\n",
    "        group[\"ruler\"] = ruler\n",
    "    group[\"num_coins\"] = 1\n",
    "    group[\"coin_group_id\"] = \"FRCPL-\" + str(index)\n",
    "    group[\"created\"] = TODAY\n",
    "    group[\"imported\"] = TODAY\n",
    "    group[\"owner\"] = \"FRCPL\"\n",
    "    group[\"metal\"] = convertMetal(row[\"Material\"])\n",
    "    freq[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])].append(group)\n",
    "    groups.append(group)\n",
    "getNums(groups) # combines duplicates and assigns num_coins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(groups)\n",
    "df2.to_csv(\"final_frcpl_groups.csv\", encoding='utf16', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
